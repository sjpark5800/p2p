<Poster Width="1734" Height="1214">
	<Panel left="36" right="192" width="398" height="289">
		<Text>Task</Text>
		<Text></Text>
		<Figure left="100" right="244" width="91" height="89" no="1" OriWidth="0" OriHeight="0
" />
		<Text> Fully annotated</Text>
		<Figure left="264" right="243" width="94" height="91" no="2" OriWidth="0" OriHeight="0" />
		<Text> Weakly annotated</Text>
		<Text>ïƒ˜ Many computer vision tasks require fully annotated data, but</Text>
		<Text>ïƒ¼ Time-consuming, Laborious, Human various</Text>
		<Text>ïƒ˜ More and more online media sharing websites (e.g. Flickr) provide</Text>
		<Text>weakly annotated data, However,</Text>
		<Text>ïƒ¼ Weaker supervision, Ambiguity (background clutter, occlusionâ€¦)</Text>
		<Text>ïƒ˜ Challenge: Weakly Supervised Object Localisation (WSOL).</Text>
	</Panel>

	<Panel left="36" right="482" width="397" height="696">
		<Text>Existing Approaches vs. Ours</Text>
		<Text>Three types of cues are exploited in existing WSOL:</Text>
		<Text>ïƒ¼ Object-saliency: A region containing the object should look different</Text>
		<Text>from background in general.</Text>
		<Text>ïƒ¼ Intra-class: The region should look similar to other regions containing</Text>
		<Text>the object of interest in other training images.</Text>
		<Text>ïƒ¼ Inter-class: The region should look dissimilar to any regions that are</Text>
		<Text>known to not contain the object of interest.</Text>
		<Text>However, they are independently trained:</Text>
		<Figure left="39" right="671" width="396" height="273" no="3" OriWidth="0.390751" OriHeight="0.189455
" />
		<Text>Independent learning ignores the fact that:</Text>
		<Text>ïƒ¼ The knowledge that multiple objects co-exist within each image is</Text>
		<Text>not exploited.</Text>
		<Text>ïƒ¼ The background is relevant to different foreground object classes.</Text>
		<Text>Our contributions:</Text>
		<Text>ïƒ¼ We propose the novel concept of joint modelling of all object</Text>
		<Text>classes and backgrounds for weakly supervised object localisation.</Text>
		<Text>ïƒ¼ We formulate a novel Bayesian topic model suitable for localization</Text>
		<Text>of objects and utilizing various types of prior knowledge available.</Text>
		<Text>ïƒ¼ We provide a solution for exploiting unlabeled data for semi+weakly</Text>
		<Text>supervised learning of object localisation.</Text>
	</Panel>

	<Panel left="455" right="194" width="820" height="407">
		<Text>Methodology</Text>
		<Text>Preprocessing and Representation:</Text>
		<Text>ïƒ¼ Regular Grid SIFT Descriptors. Sampled every 5 pixels.</Text>
		<Text>ïƒ¼ Quantising using ğ‘ğ‘£ = 2000 word codebook.</Text>
		<Text>ïƒ¼ Words and corresponding locations:</Text>
		<Text>Our Model:</Text>
		<Figure left="460" right="354" width="401" height="239" no="4" OriWidth="0.363584" OriHeight="0.146113
" />
		<Text>Observed variables:</Text>
		<Text>ğ½ïƒ¼ ÎŸ = {ğ‘¥ğ‘— , ğ‘™ğ‘— }</Text>
		<Text>ğ‘—=1Low-level feature words and corresponding location</Text>
		<Text>Latent variables:</Text>
		<Text>ïƒ¼ H=For each topic k and image jğ¾,ğ½{{ğœ‹ğ‘˜ }ğ¾</Text>
		<Text>ğ‘˜=1 , {ğ‘¦ğ‘— , ğœ‡ğ‘˜ğ‘— , Î› ğ‘˜ğ‘— , ğœƒğ‘— }</Text>
		<Text>ğ‘˜=1,ğ‘—=1 }</Text>
		<Text>Given parameters:</Text>
		<Text>Label information and priorğ½, {ğ›¼ğ‘— }</Text>
		<Text>ğ‘—=1ğ‘˜=1ğ¾</Text>
		<Text>ğœ‹ğ‘˜0 , ğœ‡ğ‘˜0 , Î›0</Text>
		<Text>ğ‘˜ , ğ›½ğ‘˜0 , ğœˆğ‘˜0ïƒ¼ Î =</Text>
		<Text>Joint distribution:</Text>
		<Text>ğ‘ ğ‘¥ğ‘–ğ‘— ğ‘¦ğ‘–ğ‘— , ğœƒğ‘— ğ‘ ğ‘¦ğ‘–ğ‘— ğœƒğ‘—</Text>
		<Text>ğ‘˜ğ‘(ğœ‹ğ‘˜ |ğœ‹ğ‘˜0 )</Text>
		<Text>ğ‘–ğ‘—ğ‘—</Text>
		<Text>ğ‘ ğœ‡ğ‘—ğ‘˜ , Î›ğ‘—ğ‘˜ ğœ‡ğ‘˜0 , Î›0</Text>
		<Text>ğ‘˜ , ğ›½ğ‘˜0 , ğœˆğ‘˜0 )ğ‘(ğœƒğ‘— |ğ›¼ğ‘— )ğ‘ ğ‘‚, ğ» Î  =ğ‘ ğ‘¥ğ‘–ğ‘— ğ‘¦ğ‘–ğ‘— , ğœƒğ‘— ğ‘ ğ‘¦ğ‘–ğ‘— ğœƒğ‘—</Text>
		<Text>ğ‘˜ğ‘(ğœ‹ğ‘˜ |ğœ‹ğ‘˜0 )</Text>
		<Text>ğ‘–ğ‘—ğ‘ğ‘—</Text>
		<Text>ğ‘ ğœ‡ğ‘—ğ‘˜ , Î›ğ‘—ğ‘˜ ğœ‡ğ‘˜0 , Î›0</Text>
		<Text>ğ‘˜ , ğ›½ğ‘˜0 , ğœˆğ‘˜0 )ğ‘(ğœƒğ‘— |ğ›¼ğ‘— )ğ‘ ğ‘‚, ğ» Î  =ğ¾ğ½</Text>
		<Text>Prior Knowledge:</Text>
		<Text>ïƒ˜ Human knowledge objects and their relationships with backgrounds</Text>
		<Text>ïƒ¼ Objects are compact whilst background spread across the image.</Text>
		<Text>ïƒ¼ Objects stand out against background.</Text>
		<Text>ïƒ˜ Transferred knowledge</Text>
		<Text>ïƒ¼ Appearance and Geometry information from existing dataset.</Text>
		<Text>Object Localisation:</Text>
		<Text>ïƒ¼ Our-Gaussian Aligning a window to the ellipse obtained from q ğœ‡, Î›</Text>
		<Text>ïƒ¼ Our-Sampling Non-maximum suppression sampling over heat-map</Text>
	</Panel>

	<Panel left="455" right="602" width="818" height="203">
		<Text>Results</Text>
		<Text>Dataset: PASCAL VOC 2007. Three variants are used:</Text>
		<Text>ïƒ¼ VOC07-6Ã—2 : 6 classes with Left and Right poses, 12 classes in total.</Text>
		<Text>ïƒ¼ VOC07-14: 14 classes, other 6 were used as annotated auxiliary data</Text>
		<Text>ïƒ¼ VOC07-20: all 20 classes, each class contain all pose data.</Text>
		<Text>PASCAL criterion:</Text>
		<Text>ïƒ¼ intersection-over-union > 0.5 between Ground-Truth and predicted box</Text>
		<Text>Comparison with state-of-the-art</Text>
		<Text>ïƒ¼ Initialisation: Localising object of interest in weakly labelled images.</Text>
		<Text>ïƒ¼ Refined by detector: A conventional object detector can be trained</Text>
		<Text>using initial annotation. Then it can be used to refine object location.</Text>
		<Figure left="874" right="634" width="403" height="175" no="5" OriWidth="0.375145" OriHeight="0.152368
" />
	</Panel>

	<Panel left="455" right="805" width="819" height="372">
		<Text>Example: Foreground Topics</Text>
		<Text></Text>
		<Figure left="458" right="840" width="818" height="212" no="6" OriWidth="0.775145" OriHeight="0.16622
" />
		<Text>Figs. (c) and (d) illustrate that the object of interest â€œexplain awayâ€</Text>
		<Text>other objects of no interest.</Text>
		<Text>ïƒ¼ A car is successfully located in Fig. (c) using the heat map of car topic.ïƒ¼</Text>
		<Text>ïƒ¼Fig. (d) shows that the motorbike heat map is quite accurately</Text>
		<Text>selective, with minimal response obtained on the other vehicular clutter.</Text>
		<Text>ïƒ¼Fig. (e) indicates how the Gaussian can sometimes give a better location.</Text>
		<Text>ïƒ¼Fig. (f) shows that the single Gaussian assumption is not ideal when the</Text>
		<Text>foreground topic has a less compact response.</Text>
		<Text>ïƒ¼A failure case is shown in Fig. (g), where a bridge structure resembles</Text>
		<Text>the boat in Fig (a) resulting strong response from the foreground topic,</Text>
		<Text>whilst the actual boat topic is small and overwhelmed.</Text>
	</Panel>

	<Panel left="1294" right="193" width="400" height="512">
		<Text>Example: Background Topics</Text>
		<Text></Text>
		<Figure left="1308" right="229" width="378" height="336" no="7" OriWidth="0.327168" OriHeight="0.257373
" />
		<Text>Background non-annotated data has been modelled in our framework.ïƒ˜</Text>
		<Text>Irrelevant pixels will be explained to reduce confusion with object.</Text>
		<Text>Automatically learned background topics have clear semantic meanings,</Text>
		<Text>corresponding to common components as shown in the Figure.</Text>
		<Text>ïƒ˜ Some background components are mixed, e.g. the water topic gives</Text>
		<Text>strong response to both water and sky. But this is understandable</Text>
		<Text>since water and sky are almost visually indistinguishable in the image.</Text>
	</Panel>

	<Panel left="1295" right="705" width="399" height="292">
		<Text>Example: Semi-supervised Learning</Text>
		<Figure left="1303" right="745" width="396" height="139" no="8" OriWidth="0.37341" OriHeight="0.101877
" />
		<Text>ğ‘“ğ‘”ïƒ˜ Unknown image can set as ğ›¼</Text>
		<Text>ğ‘— =0.1. (soft constraint)</Text>
		<Text>ïƒ˜ 10% labelled data + 90% unlabeled data (relevant) or unrelated data</Text>
		<Text>ïƒ˜ Evaluating on (1) initially annotated 10% data (standard WSOL).</Text>
		<Text>(2) testing part dataset (localize objects in new images</Text>
		<Text>ïƒ˜ The figure clearly shows unlabeled data helps to learn a better object</Text>
		<Text>model.</Text>
	</Panel>

	<Panel left="1296" right="998" width="397" height="180">
		<Text>References</Text>
		<Text>[1] T. Deselaers, B. Alexe, and V. Ferrari. Weakly supervised localization</Text>
		<Text>and learning with generic knowledge. IJCV. 2012.</Text>
		<Text>[2] M. Pandey and S. Lazebnik. Scene recognition and weakly supervised</Text>
		<Text>object localization with deformable part-based models. In ICCV, 2011</Text>
		<Text>[3] P. Siva and T. Xiang. Weakly supervised object detector learning with</Text>
		<Text>model drift detection. In ICCV, 2011.</Text>
		<Text>[4] P. Siva, C. Russell, and T. Xiang. In defence of negative mining for</Text>
		<Text>annotating weakly labelled data. In ECCV, 2012.</Text>
	</Panel>

</Poster>